[2016-05-03 09:28:17,391] INFO: tpe_transform took 0.031998 seconds
[2016-05-03 09:28:17,391] INFO: TPE using 0 trials
[2016-05-03 09:28:17,402] INFO: ==================================================
[2016-05-03 09:28:17,402] INFO: Task
[2016-05-03 09:28:17,402] INFO:       [Feat@level2_meta_linear_201605030922]_[Learner@reg_ensembler]_[Id@1]
[2016-05-03 09:28:17,403] INFO: Param
[2016-05-03 09:28:17,404] INFO:       learner_list: [Ridge(alpha=4.381023517937016, copy_X=True, fit_intercept=True, max_iter=None,
   normalize=False, random_state=2016, solver='auto', tol=0.001), KerasDNNRegressor(input_dropout=0.100000, hidden_layers=3, hidden_units=32, hidden_activation='relu', hidden_dropout=0.100000, batch_norm='after_act', optimizer='adam', nb_epoch=18, batch_size=32), XGBRegressor(booster='gbtree', base_score=2.381634, colsample_bylevel=0.300000, colsample_bytree=1.000000, gamma=0.000707, learning_rate=0.022000, max_delta_step=0.000000, max_depth=4, min_child_weight=0.000000, missing='nan', n_estimators=210, nthread=14, objective='reg:linear', reg_alpha=0.004626, reg_lambda=0.000000, reg_lambda_bias=0.000000, seed=2016, silent=1, subsample=0.550000), ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=5,
          max_features=0.9500000000000001, max_leaf_nodes=None,
          min_samples_leaf=3, min_samples_split=11,
          min_weight_fraction_leaf=0.0, n_estimators=540, n_jobs=14,
          oob_score=False, random_state=2016, verbose=0, warm_start=False), RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=4,
           max_features=0.4, max_leaf_nodes=None, min_samples_leaf=1,
           min_samples_split=4, min_weight_fraction_leaf=0.0,
           n_estimators=320, n_jobs=14, oob_score=False, random_state=2016,
           verbose=0, warm_start=False)]
[2016-05-03 09:28:17,404] INFO:       weight_list: [4.0, 1.0, 1.0, 1.0, 1.0]
[2016-05-03 09:28:17,404] INFO: Result
[2016-05-03 09:28:17,404] INFO:       Run      RMSE        Shape
[2016-05-03 09:29:47,486] INFO:         1     0.43453    12259 x 300
[2016-05-03 09:31:13,017] INFO:         2    0.437023    12594 x 300
[2016-05-03 09:32:38,417] INFO:         3    0.435316    12686 x 300
[2016-05-03 09:34:04,386] INFO:         4    0.437142    12596 x 300
[2016-05-03 09:35:27,690] INFO:         5     0.43631    12589 x 300
[2016-05-03 09:35:27,914] INFO: RMSE
[2016-05-03 09:35:27,915] INFO:       Mean: 0.436064
[2016-05-03 09:35:27,915] INFO:       Std: 0.001005
[2016-05-03 09:35:27,915] INFO: Time
[2016-05-03 09:35:27,915] INFO:       7 mins
[2016-05-03 09:35:27,915] INFO: --------------------------------------------------
[2016-05-03 10:00:03,212] INFO: tpe_transform took 0.034648 seconds
[2016-05-03 10:00:03,212] INFO: TPE using 1/1 trials with best loss 0.436064
[2016-05-03 10:00:03,224] INFO: ==================================================
[2016-05-03 10:00:03,224] INFO: Task
[2016-05-03 10:00:03,224] INFO:       [Feat@level2_meta_linear_201605030922]_[Learner@reg_ensembler]_[Id@2]
[2016-05-03 10:00:03,224] INFO: Param
[2016-05-03 10:00:03,226] INFO:       learner_list: [Ridge(alpha=1.8726310964947848, copy_X=True, fit_intercept=True,
   max_iter=None, normalize=True, random_state=2016, solver='auto',
   tol=0.001), KerasDNNRegressor(input_dropout=0.000000, hidden_layers=1, hidden_units=128, hidden_activation='relu', hidden_dropout=0.150000, batch_norm='after_act', optimizer='adam', nb_epoch=16, batch_size=80), XGBRegressor(booster='gbtree', base_score=2.381634, colsample_bylevel=1.000000, colsample_bytree=1.000000, gamma=0.942167, learning_rate=0.006000, max_delta_step=0.000000, max_depth=9, min_child_weight=7.627526, missing='nan', n_estimators=900, nthread=14, objective='reg:linear', reg_alpha=0.000144, reg_lambda=0.000141, reg_lambda_bias=0.000000, seed=2016, silent=1, subsample=1.000000), ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=9,
          max_features=0.35000000000000003, max_leaf_nodes=None,
          min_samples_leaf=10, min_samples_split=2,
          min_weight_fraction_leaf=0.0, n_estimators=950, n_jobs=14,
          oob_score=False, random_state=2016, verbose=0, warm_start=False), RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=1,
           max_features=0.2, max_leaf_nodes=None, min_samples_leaf=7,
           min_samples_split=4, min_weight_fraction_leaf=0.0,
           n_estimators=610, n_jobs=14, oob_score=False, random_state=2016,
           verbose=0, warm_start=False)]
[2016-05-03 10:00:03,226] INFO:       weight_list: [4.0, 1.0, 1.0, 1.0, 1.0]
[2016-05-03 10:00:03,226] INFO: Result
[2016-05-03 10:00:03,226] INFO:       Run      RMSE        Shape
[2016-05-03 10:04:12,866] INFO:         1    0.435108    12259 x 300
[2016-05-03 10:08:14,963] INFO:         2    0.437629    12594 x 300
[2016-05-03 10:12:31,763] INFO:         3    0.435753    12686 x 300
[2016-05-03 10:16:58,848] INFO:         4    0.437806    12596 x 300
[2016-05-03 10:21:07,804] INFO:         5    0.436877    12589 x 300
[2016-05-03 10:21:08,029] INFO: RMSE
[2016-05-03 10:21:08,029] INFO:       Mean: 0.436635
[2016-05-03 10:21:08,029] INFO:       Std: 0.001051
[2016-05-03 10:21:08,029] INFO: Time
[2016-05-03 10:21:08,030] INFO:       21 mins
[2016-05-03 10:21:08,030] INFO: --------------------------------------------------
[2016-05-03 11:29:15,736] INFO: tpe_transform took 0.033550 seconds
[2016-05-03 11:29:15,737] INFO: TPE using 2/2 trials with best loss 0.436064
[2016-05-03 11:29:15,747] INFO: ==================================================
[2016-05-03 11:29:15,747] INFO: Task
[2016-05-03 11:29:15,748] INFO:       [Feat@level2_meta_linear_201605030922]_[Learner@reg_ensembler]_[Id@3]
[2016-05-03 11:29:15,748] INFO: Param
[2016-05-03 11:29:15,749] INFO:       learner_list: [Ridge(alpha=0.012492657184290833, copy_X=True, fit_intercept=True,
   max_iter=None, normalize=True, random_state=2016, solver='auto',
   tol=0.001), KerasDNNRegressor(input_dropout=0.100000, hidden_layers=2, hidden_units=32, hidden_activation='relu', hidden_dropout=0.450000, batch_norm='after_act', optimizer='rmsprop', nb_epoch=16, batch_size=96), XGBRegressor(booster='gbtree', base_score=2.381634, colsample_bylevel=0.350000, colsample_bytree=1.000000, gamma=0.000008, learning_rate=0.004000, max_delta_step=0.000000, max_depth=5, min_child_weight=0.000002, missing='nan', n_estimators=390, nthread=14, objective='reg:linear', reg_alpha=0.000002, reg_lambda=0.035105, reg_lambda_bias=0.000000, seed=2016, silent=1, subsample=0.450000), ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=10,
          max_features=0.45, max_leaf_nodes=None, min_samples_leaf=14,
          min_samples_split=5, min_weight_fraction_leaf=0.0,
          n_estimators=400, n_jobs=14, oob_score=False, random_state=2016,
          verbose=0, warm_start=False), RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=7,
           max_features=0.8500000000000001, max_leaf_nodes=None,
           min_samples_leaf=7, min_samples_split=12,
           min_weight_fraction_leaf=0.0, n_estimators=310, n_jobs=14,
           oob_score=False, random_state=2016, verbose=0, warm_start=False)]
[2016-05-03 11:29:15,749] INFO:       weight_list: [4.0, 1.0, 1.0, 1.0, 1.0]
[2016-05-03 11:29:15,749] INFO: Result
[2016-05-03 11:29:15,749] INFO:       Run      RMSE        Shape
[2016-05-03 11:31:00,151] INFO:         1    0.434506    12259 x 300
[2016-05-03 11:32:47,153] INFO:         2    0.437037    12594 x 300
[2016-05-03 11:34:32,172] INFO:         3    0.435529    12686 x 300
[2016-05-03 11:36:16,693] INFO:         4    0.437059    12596 x 300
[2016-05-03 11:38:03,332] INFO:         5    0.436313    12589 x 300
[2016-05-03 11:38:03,567] INFO: RMSE
[2016-05-03 11:38:03,567] INFO:       Mean: 0.436089
[2016-05-03 11:38:03,567] INFO:       Std: 0.000970
[2016-05-03 11:38:03,568] INFO: Time
[2016-05-03 11:38:03,568] INFO:       8 mins
[2016-05-03 11:38:03,568] INFO: --------------------------------------------------
